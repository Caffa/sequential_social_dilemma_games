[flags]
# Experiment flags

env_docstring = Name of the environment to use. Can be cleanup or harvest.
env = cleanup
num_agents_docstring = Number of agent policies.
num_agents = 5

tune_docstring = Set to True to do hyperparameter tuning.
tune = False
debug_docstring = Set to true to run in a debugging / testing mode with less memory.
debug = False
resume_docstring = Set to true to resume a previously stopped experiment.
resume = False

# Hardware flags

num_cpus_docstring = Number of available CPUs.
num_cpus = 2
num_gpus_docstring = Number of available GPUs.
num_gpus = 0

use_gpus_for_workers_docstring = Set to true to run workers on GPUs rather than CPUs.
use_gpus_for_workers = False
use_gpu_for_driver_docstring = Set to true to run driver on GPU rather than CPU.
use_gpu_for_driver = False
num_workers_per_device_docstring = Number of workers to place on a single device (CPU or GPU).
num_workers_per_device = 1


[parameters_cleanup]
lr_init = 0.00126
lr_final = 0.000012
entropy_coeff = -.00176
# Add arbitrary amount of entropy tuning parameters - must start with entropy_tune, is processed in order
entropy_tune_0 = 0
entropy_tune_1 = -1e-1

[parameters_harvest]
lr_init = 0.00136
lr_final = 0.000028
entropy_coeff = -.000687
# Add arbitrary amount of entropy tuning parameters - must start with entropy_tune, is processed in order
entropy_tune_0 = 0
entropy_tune_1 = -1e-1
entropy_tune_2 = -1e-2


[network]
# Optional Redis address. If this address is not provided, a local Redis server is automatically started.
# Leave empty if not used.
redis_address =
# Optional server address to sync training results to.
# Leave empty if not used.
upload_dir =
